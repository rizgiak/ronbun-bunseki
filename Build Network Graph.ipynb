{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import util\n",
    "from journal_api.journal_api import JournalAPI\n",
    "from IPython.display import JSON\n",
    "import xml.etree.ElementTree as ET\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import logging\n",
    "import yaml\n",
    "from journal_api import semanticscholar_api"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('logging_config.yaml', 'r') as config_file:\n",
    "    log_config = yaml.safe_load(config_file)\n",
    "logging.config.dictConfig(log_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Design and Control of Roller Grasper V2 for In-Hand Manipulation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-28 16:21:07,709 - DEBUG - ss.search: Found! title=Design and Control of Roller Grasper V2 for In-Hand Manipulation\n"
     ]
    },
    {
     "data": {
      "application/json": {
       "abstract": "The ability to perform in-hand manipulation still remains an unsolved problem; having this capability would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects. In this work, we present a novel non-anthropomorphic robot grasper with the ability to manipulate objects by means of active surfaces at the fingertips. Active surfaces are achieved by spherical rolling fingertips with two degrees of freedom (DoF) - a pivoting motion for surface reorientation - and a continuous rolling motion for moving the object. A further DoF is in the base of each finger, allowing the fingers to grasp objects over a range of size and shapes. Instantaneous kinematics was derived and objects were successfully manipulated both with a custom handcrafted control scheme as well as one learned through imitation learning, in simulation and experimentally on the hardware.",
       "authors": [
        "Shenli Yuan",
        "Lin Shao",
        "Connor L. Yako",
        "Alexander M. Gruebele",
        "J. Salisbury"
       ],
       "fieldsOfStudy": [
        "Computer Science",
        "Engineering"
       ],
       "paperId": "5d0c16d8532b4514dc4a330562e44d21c3dbaeff",
       "references": [
        "Concept2Robot: Learning manipulation concepts from instructions and human demonstrations",
        "Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation",
        "Design\nand Analysis of a Multimodal Grasper Having Shape Conformity and Within-Hand Manipulation With\nAdjustable Contact Forces",
        "A Century of Robotic Hands",
        "Dual-Arm In-Hand Manipulation and Regrasping Using Dexterous Manipulation Graphs",
        "Learning dexterous in-hand manipulation",
        "In-Hand Manipulation via Motion Cones",
        "Dexterous Manipulation Graphs"
       ],
       "source": "semanticscholar",
       "title": "Design and Control of Roller Grasper V2 for In-Hand Manipulation",
       "tldr": "This work presents a novel non-anthropomorphic robot grasper with the ability to manipulate objects by means of active surfaces at the fingertips, which would allow robots to perform sophisticated tasks requiring repositioning and reorienting of grasped objects.",
       "year": 2020
      },
      "text/plain": [
       "<IPython.core.display.JSON object>"
      ]
     },
     "execution_count": 17,
     "metadata": {
      "application/json": {
       "expanded": false,
       "root": "root"
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "journal = JournalAPI()\n",
    "dt = journal.search(title, 2018, find_references=False, fix_references=False)\n",
    "JSON(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def source_target(source, target):\n",
    "    ret = pd.DataFrame(columns=[\"source\", \"target\"])\n",
    "    for t in target:\n",
    "        ret = ret.append({\"source\": source, \"target\": t}, ignore_index=True)\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = None\n",
    "def source_target_generator(title, title_list, level = 1, start_year = 2017, fix_references = False):\n",
    "    global df\n",
    "    ret = pd.DataFrame(columns=[\"source\", \"target\"])\n",
    "    if(level > 0):\n",
    "        logging.info(f\"source_target_generator: level={level}, len={len(title_list)}, title={title}\")\n",
    "        for index, title in enumerate(title_list):\n",
    "            logging.info(f\"source_target_generator: ({index+1}/{len(title_list)}) title={title}\")\n",
    "            src = journal.search(title, start_year, find_references=True, fix_references=fix_references)\n",
    "            if src != None:\n",
    "                # TODO: Create global variable to store detailed info of paper\n",
    "                if df is None or df.empty:\n",
    "                    df = pd.DataFrame([src])\n",
    "                else:\n",
    "                    matching_rows = df[(df[\"title\"] == src[\"title\"])]\n",
    "                    if matching_rows.empty:\n",
    "                        new_row = pd.Series(src)\n",
    "                        df = df.append(new_row, ignore_index=True)\n",
    "                    else:\n",
    "                        logging.debug(f\"source_target_generator: Title already exists. title={src['title']}\")\n",
    "                \n",
    "                st = source_target(src[\"title\"],src[\"references\"])\n",
    "                ret = pd.concat([ret, st], ignore_index=True)\n",
    "                lv = level - 1\n",
    "                if lv == 1:\n",
    "                    ret = pd.concat([ret, source_target_generator(src[\"title\"], src[\"references\"], lv, start_year)], ignore_index=True)\n",
    "                else:\n",
    "                    ret = pd.concat([ret, source_target_generator(src[\"title\"], src[\"references\"], lv, start_year, fix_references)], ignore_index=True)\n",
    "            \n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-08-28 16:34:19,819 - INFO - source_target_generator: level=2, len=1, title=\n",
      "2023-08-28 16:34:19,821 - INFO - source_target_generator: (1/1) title=Design and Control of Roller Grasper V2 for In-Hand Manipulation\n",
      "2023-08-28 16:34:20,429 - DEBUG - ss.search: Found! title=Design and Control of Roller Grasper V2 for In-Hand Manipulation\n",
      "2023-08-28 16:34:20,448 - INFO - source_target_generator: level=1, len=8, title=Design and Control of Roller Grasper V2 for In-Hand Manipulation\n",
      "2023-08-28 16:34:20,450 - INFO - source_target_generator: (1/8) title=Concept2Robot: Learning manipulation concepts from instructions and human demonstrations\n",
      "2023-08-28 16:34:21,049 - DEBUG - ss.search: Found! title=Concept2Robot: Learning manipulation concepts from instructions and human demonstrations\n",
      "2023-08-28 16:34:21,115 - INFO - source_target_generator: (2/8) title=Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation\n",
      "2023-08-28 16:34:21,600 - DEBUG - ss.search: Found! title=Design of a Roller-Based Dexterous Hand for Object Grasping and Within-Hand Manipulation\n",
      "2023-08-28 16:34:21,609 - INFO - source_target_generator: (3/8) title=Design\n",
      "and Analysis of a Multimodal Grasper Having Shape Conformity and Within-Hand Manipulation With\n",
      "Adjustable Contact Forces\n",
      "2023-08-28 16:34:22,178 - DEBUG - ss.search: Found! title=Design\n",
      "and Analysis of a Multimodal Grasper Having Shape Conformity and Within-Hand Manipulation With\n",
      "Adjustable Contact Forces\n",
      "2023-08-28 16:34:22,189 - INFO - source_target_generator: (4/8) title=A Century of Robotic Hands\n",
      "2023-08-28 16:34:22,677 - DEBUG - ss.search: Found! title=A Century of Robotic Hands\n",
      "2023-08-28 16:34:22,677 - WARNING - ss._remake_tldr: No tldr!\n",
      "2023-08-28 16:34:22,681 - WARNING - ss._remake_references: No references!\n",
      "2023-08-28 16:34:24,058 - DEBUG - cr.search: Found! title=A Century of Robotic Hands\n",
      "2023-08-28 16:34:24,059 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:24,060 - DEBUG - {'key': 'B1', 'first-page': '4', 'volume': '2', 'author': 'Alpenfels EJ', 'year': '1955', 'journal-title': 'Artif. Limbs'}\n",
      "2023-08-28 16:34:28,142 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:28,143 - DEBUG - {'key': 'B9', 'unstructured': '9.\\u2002 Shadow Robot Co.  2018.  Shadow Dexterous Hand.  Shadow Robot Company.  https://www.shadowrobot.com/products/dexterous-hand'}\n",
      "2023-08-28 16:34:31,567 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:31,568 - DEBUG - {'key': 'B15', 'first-page': '31', 'volume': '8', 'author': 'Vujaklija I', 'year': '2016', 'journal-title': 'Orthop. Res. Rev'}\n",
      "2023-08-28 16:34:34,554 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:34,555 - DEBUG - {'key': 'B20', 'unstructured': '20.\\u2002 IEEE Tech. Comm. Robot. Hand Grasping Manip.  2016.  Robotic Grasping and Manipulation Competition.  IEEE Technical Committee on Robotic Hand Grasping and Manipulation.  http://www.rhgm.org/activities/competition_iros2016'}\n",
      "2023-08-28 16:34:34,556 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:34,558 - DEBUG - {'key': 'B21', 'unstructured': '21.\\u2002 Dipo Power.  2018.  Dipo Power website.  http://dipo-power.com'}\n",
      "2023-08-28 16:34:39,408 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:39,409 - DEBUG - {'key': 'B32', 'unstructured': '32.\\u2002 Becker Mech. Hand Co.  2018.  Products.  Becker Mechanical Hand Company.  http://www.beckermechanicalhand.com/products'}\n",
      "2023-08-28 16:34:39,411 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:39,412 - DEBUG - {'key': 'B33', 'first-page': '133', 'volume': '4', 'author': 'Reiter R', 'year': '1948', 'journal-title': 'Grenzgebiete Med.'}\n",
      "2023-08-28 16:34:40,064 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:40,065 - DEBUG - {'key': 'B36', 'first-page': '1268', 'volume': '91', 'author': 'Sherman ED', 'year': '1964', 'journal-title': 'Can. Med. Assoc. J.'}\n",
      "2023-08-28 16:34:40,843 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:40,845 - DEBUG - {'key': 'B39', 'unstructured': '39.\\u2002 Ottobock.  2018.  Solution overview: upper limb prosthetics.  Ottobock.  http://www.ottobockus.com/prosthetics/upper-limb-prosthetics/solution-overview/'}\n",
      "2023-08-28 16:34:42,216 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:42,218 - DEBUG - {'key': 'B42', 'unstructured': '42.\\u2002 TRS.  2018.  About TRS.  TRS.  http://www.trsprosthetics.com/about-trs'}\n",
      "2023-08-28 16:34:43,699 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:43,700 - DEBUG - {'key': 'B46', 'unstructured': '46.\\u2002 SCHUNK.  1983.  Milestones of innovation.  SCHUNK.  https://schunk.com/fi_en/company/about-schunk/innovation-milestones'}\n",
      "2023-08-28 16:34:58,069 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:34:58,070 - DEBUG - {'key': 'B72', 'first-page': '1', 'volume': '4', 'author': 'Laliberté T', 'year': '2002', 'journal-title': 'Mach. Intell. Robot. Control'}\n",
      "2023-08-28 16:35:04,427 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:04,428 - DEBUG - {'key': 'B81', 'unstructured': '81.\\u2002 Matsuda  H.  2004.  Multi-finger hand device.  EP Patent Appl. EP20020758875'}\n",
      "2023-08-28 16:35:11,895 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:11,896 - DEBUG - {'key': 'B93', 'unstructured': '93.\\u2002 Touch  Bionics.  2018.  History.  Touch Bionics.  http://www.touchbionics.com/about/history'}\n",
      "2023-08-28 16:35:11,897 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:11,898 - DEBUG - {'key': 'B94', 'unstructured': '94.\\u2002 Elumotion.  2018.  Elumotion website.  http://elumotion.com'}\n",
      "2023-08-28 16:35:21,199 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:21,201 - DEBUG - {'key': 'B113', 'unstructured': '113.\\u2002 PAL Robot.  2018.  Products.  PAL Robotics.  https://www.pal-robotics.com/en/products'}\n",
      "2023-08-28 16:35:21,888 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:21,889 - DEBUG - {'key': 'B115', 'unstructured': '115.\\u2002 Ottobock.  2011.  Michelangelo prosthetic hand.  Ottobock.  http://www.ottobockus.com/prosthetics/upper-limb-prosthetics/solution-overview/michelangelo-prosthetic-hand/'}\n",
      "2023-08-28 16:35:24,735 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:24,736 - DEBUG - {'key': 'B123', 'unstructured': '123.\\u2002 ITK.  2011.  The “Handroid”.  ITK.  http://www.itk-pro.com/en/pro/kindengisyu.htm'}\n",
      "2023-08-28 16:35:24,737 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:24,738 - DEBUG - {'key': 'B124', 'unstructured': '124.\\u2002 Wonik Robot.  2018.  History.  Wonik Robotics.  http://www.simlab.co.kr/History.htm'}\n",
      "2023-08-28 16:35:27,462 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:27,463 - DEBUG - {'key': 'B132', 'unstructured': '132.\\u2002 Vincent Syst.  2018.  VINCENTevolution 3.  Vincent Systems.  https://vincentsystems.de/en/prosthetics/vincent-evolution-3'}\n",
      "2023-08-28 16:35:56,433 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:35:56,434 - DEBUG - {'issue': '4', 'key': 'B180', 'volume': '14', 'author': 'Hao Y', 'year': '2017', 'journal-title': 'Int. J. Adv. Robot. Syst.'}\n",
      "2023-08-28 16:36:11,397 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:36:11,399 - DEBUG - {'key': 'B201', 'unstructured': '201.\\u2002 Taska Prosthet.  2018.  Taska Prosthetics website.  http://www.taskaprosthetics.com'}\n",
      "2023-08-28 16:36:15,474 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:36:15,475 - DEBUG - {'key': 'B210', 'unstructured': '210.\\u2002 Rehab Technol. Lab.  2018.  Sviluppo dispositivi medici.  Rehab Technologies Lab.  http://rehab.iit.it/sviluppo-dispositivi'}\n",
      "2023-08-28 16:36:27,808 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:36:27,809 - DEBUG - {'key': 'B231', 'unstructured': '231.\\u2002 Nat. Mach. Motion Init.  2017.  Natural Machine Motion Initiative website.  https://www.naturalmachinemotioninitiative.com'}\n",
      "2023-08-28 16:36:27,810 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:36:27,811 - DEBUG - {'key': 'B232', 'unstructured': '232.\\u2002 Tech. Univ. Berlin.  2016.  Soft Hands.  Technische Universität Berlin Department of Computer Engineering and Microelectronics.  http://www.robotics.tu-berlin.de/menue/research/soft_hands'}\n",
      "2023-08-28 16:36:27,812 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:36:27,813 - DEBUG - {'key': 'B233', 'unstructured': '233.\\u2002 e-NABLE.  2018.  About us.  Enabling the Future.  http://enablingthefuture.org/about'}\n",
      "2023-08-28 16:36:29,369 - WARNING - cr._remake_references: No information of reference\n",
      "2023-08-28 16:36:29,370 - DEBUG - {'key': 'B240', 'first-page': '591', 'volume': '60', 'author': 'Easton TA', 'year': '1972', 'journal-title': 'Am. Sci.'}\n",
      "2023-08-28 16:36:36,383 - INFO - source_target_generator: (5/8) title=Dual-Arm In-Hand Manipulation and Regrasping Using Dexterous Manipulation Graphs\n",
      "2023-08-28 16:36:36,880 - DEBUG - ss.search: Found! title=Dual-Arm In-Hand Manipulation and Regrasping Using Dexterous Manipulation Graphs\n",
      "2023-08-28 16:36:36,881 - WARNING - ss._remake_references: Unknown year. title=She is currently a Ph.D. student at the Robotics, Perception and Learning Lab at KTH Royal Institute of Technology\n",
      "2023-08-28 16:36:36,882 - WARNING - ss._remake_references: Unknown year. title=Regrasping , ” in Robotics and Automation\n",
      "2023-08-28 16:36:36,883 - WARNING - ss._remake_references: Unknown year. title=AprilTag: A robust and ﬂexible visual ﬁducial system\n",
      "2023-08-28 16:36:36,905 - INFO - source_target_generator: (6/8) title=Learning dexterous in-hand manipulation\n",
      "2023-08-28 16:36:37,554 - DEBUG - ss.search: Found! title=Learning dexterous in-hand manipulation\n",
      "2023-08-28 16:36:37,555 - WARNING - ss._remake_references: Unknown year. title=Rectiﬁed Linear Units Improve Restricted Boltzmann Machines\n",
      "2023-08-28 16:36:37,574 - INFO - source_target_generator: (7/8) title=In-Hand Manipulation via Motion Cones\n",
      "2023-08-28 16:36:38,317 - DEBUG - ss.search: Found! title=In-Hand Manipulation via Motion Cones\n",
      "2023-08-28 16:36:38,325 - INFO - source_target_generator: (8/8) title=Dexterous Manipulation Graphs\n",
      "2023-08-28 16:36:39,157 - DEBUG - ss.search: Found! title=Dexterous Manipulation Graphs\n",
      "2023-08-28 16:36:39,159 - WARNING - ss._remake_references: Unknown year. title=Rotation (Fig. 2b)\n"
     ]
    }
   ],
   "source": [
    "x = source_target_generator(\"\", [title], 2, 2018, False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>paperId</th>\n",
       "      <th>title</th>\n",
       "      <th>abstract</th>\n",
       "      <th>year</th>\n",
       "      <th>fieldsOfStudy</th>\n",
       "      <th>tldr</th>\n",
       "      <th>authors</th>\n",
       "      <th>references</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5d0c16d8532b4514dc4a330562e44d21c3dbaeff</td>\n",
       "      <td>Design and Control of Roller Grasper V2 for In...</td>\n",
       "      <td>The ability to perform in-hand manipulation st...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Computer Science, Engineering]</td>\n",
       "      <td>This work presents a novel non-anthropomorphic...</td>\n",
       "      <td>[Shenli Yuan, Lin Shao, Connor L. Yako, Alexan...</td>\n",
       "      <td>[Concept2Robot: Learning manipulation concepts...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>c328a1ea31eaa4b357e584285ffb6ff2671b5bd4</td>\n",
       "      <td>Concept2Robot: Learning manipulation concepts ...</td>\n",
       "      <td>We aim to endow a robot with the ability to le...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>This work aims to endow a robot with the abili...</td>\n",
       "      <td>[Lin Shao, Toki Migimatsu, Qiang Zhang, Karen ...</td>\n",
       "      <td>[Model-Based Inverse Reinforcement Learning fr...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b019519f00715061b4fa05c7e8eda768f3b4779d</td>\n",
       "      <td>Design of a Roller-Based Dexterous Hand for Ob...</td>\n",
       "      <td>This paper describes the development of a nove...</td>\n",
       "      <td>2020</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>This paper describes the development of a nove...</td>\n",
       "      <td>[Shenli Yuan, A. D. Epps, Jerome B. Nowak, J. ...</td>\n",
       "      <td>[Design\\nand Analysis of a Multimodal Grasper ...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e5a3aca5321fc0e1b70fb51e4c4b6ff9dfbdb05d</td>\n",
       "      <td>Design\\nand Analysis of a Multimodal Grasper H...</td>\n",
       "      <td>\\n This paper presents the design, analysis, a...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>This paper presents the design, analysis, and ...</td>\n",
       "      <td>[Nagamanikandan Govindan, Asokan Thondiyath]</td>\n",
       "      <td>[Variable-Friction Finger Surfaces to Enable W...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>f12e6e06816b1ff34bb0673a9059065458c43bc5</td>\n",
       "      <td>A Century of Robotic Hands</td>\n",
       "      <td>This article reports on the state of the art o...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Computer Science, Engineering]</td>\n",
       "      <td></td>\n",
       "      <td>[C. Piazza, G. Grioli, M. G. Catalano, A. Bicchi]</td>\n",
       "      <td>[The evolution of functional hand replacement:...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ec5cd7e50867ee305e6adb0592e11252a0977b91</td>\n",
       "      <td>Dual-Arm In-Hand Manipulation and Regrasping U...</td>\n",
       "      <td>This work focuses on the problem of in-hand ma...</td>\n",
       "      <td>2019</td>\n",
       "      <td>[Computer Science]</td>\n",
       "      <td>This work proposes Dexterous Manipulation Grap...</td>\n",
       "      <td>[S. Cruciani, Kaiyu Hang, Christian Smith, D. ...</td>\n",
       "      <td>[Preparatory Manipulation Planning Using Autom...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>d37a34c204a8beefcaef4dddddb7a90c16e973d4</td>\n",
       "      <td>Learning dexterous in-hand manipulation</td>\n",
       "      <td>We use reinforcement learning (RL) to learn de...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[Computer Science, Mathematics]</td>\n",
       "      <td>This work uses reinforcement learning (RL) to ...</td>\n",
       "      <td>[Marcin Andrychowicz, Bowen Baker, Maciek Choc...</td>\n",
       "      <td>[The minimal exponent and $k$-rationality for ...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>9961da04571b16d282df74b624003ebb5f294063</td>\n",
       "      <td>In-Hand Manipulation via Motion Cones</td>\n",
       "      <td>In this paper, we present the mechanics and al...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[Computer Science, Engineering]</td>\n",
       "      <td>It is shown that the motion cone is defined by...</td>\n",
       "      <td>[Nikhil Chavan Dafle, Rachel Holladay, Alberto...</td>\n",
       "      <td>[Pushing revisited: Differential flatness, tra...</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>6a00746fc98248da0db1e6074090c2d513f9487d</td>\n",
       "      <td>Dexterous Manipulation Graphs</td>\n",
       "      <td>We propose the Dexterous Manipulation Graph as...</td>\n",
       "      <td>2018</td>\n",
       "      <td>[Computer Science, Engineering]</td>\n",
       "      <td>The Dexterous Manipulation Graph is proposed a...</td>\n",
       "      <td>[S. Cruciani, Christian Smith, D. Kragic, Kaiy...</td>\n",
       "      <td>[Rotation (Fig. 2b)]</td>\n",
       "      <td>semanticscholar</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    paperId  \\\n",
       "0  5d0c16d8532b4514dc4a330562e44d21c3dbaeff   \n",
       "1  c328a1ea31eaa4b357e584285ffb6ff2671b5bd4   \n",
       "2  b019519f00715061b4fa05c7e8eda768f3b4779d   \n",
       "3  e5a3aca5321fc0e1b70fb51e4c4b6ff9dfbdb05d   \n",
       "4  f12e6e06816b1ff34bb0673a9059065458c43bc5   \n",
       "5  ec5cd7e50867ee305e6adb0592e11252a0977b91   \n",
       "6  d37a34c204a8beefcaef4dddddb7a90c16e973d4   \n",
       "7  9961da04571b16d282df74b624003ebb5f294063   \n",
       "8  6a00746fc98248da0db1e6074090c2d513f9487d   \n",
       "\n",
       "                                               title  \\\n",
       "0  Design and Control of Roller Grasper V2 for In...   \n",
       "1  Concept2Robot: Learning manipulation concepts ...   \n",
       "2  Design of a Roller-Based Dexterous Hand for Ob...   \n",
       "3  Design\\nand Analysis of a Multimodal Grasper H...   \n",
       "4                         A Century of Robotic Hands   \n",
       "5  Dual-Arm In-Hand Manipulation and Regrasping U...   \n",
       "6            Learning dexterous in-hand manipulation   \n",
       "7              In-Hand Manipulation via Motion Cones   \n",
       "8                      Dexterous Manipulation Graphs   \n",
       "\n",
       "                                            abstract  year  \\\n",
       "0  The ability to perform in-hand manipulation st...  2020   \n",
       "1  We aim to endow a robot with the ability to le...  2020   \n",
       "2  This paper describes the development of a nove...  2020   \n",
       "3  \\n This paper presents the design, analysis, a...  2019   \n",
       "4  This article reports on the state of the art o...  2019   \n",
       "5  This work focuses on the problem of in-hand ma...  2019   \n",
       "6  We use reinforcement learning (RL) to learn de...  2018   \n",
       "7  In this paper, we present the mechanics and al...  2018   \n",
       "8  We propose the Dexterous Manipulation Graph as...  2018   \n",
       "\n",
       "                     fieldsOfStudy  \\\n",
       "0  [Computer Science, Engineering]   \n",
       "1               [Computer Science]   \n",
       "2               [Computer Science]   \n",
       "3               [Computer Science]   \n",
       "4  [Computer Science, Engineering]   \n",
       "5               [Computer Science]   \n",
       "6  [Computer Science, Mathematics]   \n",
       "7  [Computer Science, Engineering]   \n",
       "8  [Computer Science, Engineering]   \n",
       "\n",
       "                                                tldr  \\\n",
       "0  This work presents a novel non-anthropomorphic...   \n",
       "1  This work aims to endow a robot with the abili...   \n",
       "2  This paper describes the development of a nove...   \n",
       "3  This paper presents the design, analysis, and ...   \n",
       "4                                                      \n",
       "5  This work proposes Dexterous Manipulation Grap...   \n",
       "6  This work uses reinforcement learning (RL) to ...   \n",
       "7  It is shown that the motion cone is defined by...   \n",
       "8  The Dexterous Manipulation Graph is proposed a...   \n",
       "\n",
       "                                             authors  \\\n",
       "0  [Shenli Yuan, Lin Shao, Connor L. Yako, Alexan...   \n",
       "1  [Lin Shao, Toki Migimatsu, Qiang Zhang, Karen ...   \n",
       "2  [Shenli Yuan, A. D. Epps, Jerome B. Nowak, J. ...   \n",
       "3       [Nagamanikandan Govindan, Asokan Thondiyath]   \n",
       "4  [C. Piazza, G. Grioli, M. G. Catalano, A. Bicchi]   \n",
       "5  [S. Cruciani, Kaiyu Hang, Christian Smith, D. ...   \n",
       "6  [Marcin Andrychowicz, Bowen Baker, Maciek Choc...   \n",
       "7  [Nikhil Chavan Dafle, Rachel Holladay, Alberto...   \n",
       "8  [S. Cruciani, Christian Smith, D. Kragic, Kaiy...   \n",
       "\n",
       "                                          references           source  \n",
       "0  [Concept2Robot: Learning manipulation concepts...  semanticscholar  \n",
       "1  [Model-Based Inverse Reinforcement Learning fr...  semanticscholar  \n",
       "2  [Design\\nand Analysis of a Multimodal Grasper ...  semanticscholar  \n",
       "3  [Variable-Friction Finger Surfaces to Enable W...  semanticscholar  \n",
       "4  [The evolution of functional hand replacement:...  semanticscholar  \n",
       "5  [Preparatory Manipulation Planning Using Autom...  semanticscholar  \n",
       "6  [The minimal exponent and $k$-rationality for ...  semanticscholar  \n",
       "7  [Pushing revisited: Differential flatness, tra...  semanticscholar  \n",
       "8                               [Rotation (Fig. 2b)]  semanticscholar  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_json(\"aaa.json\", orient=\"records\", indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x.to_csv(\"test_1.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Open the JSON file for reading\n",
    "with open(\"output.json\", \"r\") as json_file:\n",
    "    data = json.load(json_file)\n",
    "\n",
    "journal = JournalAPI()\n",
    "for d in data[\"nodes\"]:\n",
    "    dt = journal.search(d[\"name\"], 2018, find_references=False, fix_references=False)\n",
    "    print(dt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from collections import defaultdict\n",
    "from pyvis.network import Network\n",
    "\n",
    "net = Network(\"1200px\", \"1200px\", notebook=True)\n",
    "\n",
    "# Example dummy data\n",
    "sources = x[\"source\"]\n",
    "targets = x[\"target\"]\n",
    "sources_short = [source[:100] + \"...\" for source in sources]\n",
    "targets_short = [target[:100] + \"...\" for target in targets]\n",
    "\n",
    "# Create a dictionary to store the count of each target\n",
    "target_counts = defaultdict(int)\n",
    "for t in targets_short:\n",
    "    target_counts[t] += 10\n",
    "    if t == \"...\":\n",
    "        target_counts[t] = 1\n",
    "\n",
    "# Create unique node labels for each occurrence of a node\n",
    "unique_nodes = {}\n",
    "for node in set(sources_short + targets_short):\n",
    "    count = target_counts[node]\n",
    "    size = count if count > 1 else 1  # Ensuring the smallest size is 1\n",
    "    unique_label = f\"{node} ({count})\"\n",
    "    net.add_node(unique_label, size=size)\n",
    "    unique_nodes[node] = unique_label\n",
    "\n",
    "# Add edges to the graph using the unique node labels\n",
    "for s, t in zip(sources_short, targets_short):\n",
    "    net.add_edge(unique_nodes[s], unique_nodes[t])\n",
    "\n",
    "# Step 3: Visualize the graph in Jupyter Notebook\n",
    "net.show(\"network_graph2.html\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "ref_pd = util.string_to_df(xy[\"refs\"][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_refs = generate_title_auths_refs(ref_pd)\n",
    "xy_refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xy_refs[\"title\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "json_data = xy_refs[\"title\"].to_json(orient='records')\n",
    "\n",
    "# Specify the output file path\n",
    "output_file = 'data.json'\n",
    "\n",
    "# Write JSON data to a file\n",
    "with open(output_file, 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossref = util.crossref_search(title)\n",
    "json.dumps(crossref, ensure_ascii=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cref = crossref_search_by_doi(\"10.1177/0278364914559753\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "crossref = crossref_similar_search(title,10)\n",
    "crossref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "st = \"ALVINN: An Autonomous Land Vehicle in a Neural Network\"\n",
    "tt = google_search_books(st)\n",
    "tt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arxiv_search(\"A reduction of imitation learning and structured prediction to no-regret online learning\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "def crossref_keywords_search(keywords, rows):\n",
    "    \"\"\"\n",
    "    crossref_search\n",
    "    \"\"\"\n",
    "    # Specify the API endpoint\n",
    "    ENDPOINT = \"https://api.crossref.org/works\"\n",
    "\n",
    "    # Set up the query parameters\n",
    "    params = {\n",
    "        \"query\": \" OR \".join(keywords),\n",
    "        \"rows\": rows  # Number of results to retrieve\n",
    "    }\n",
    "\n",
    "    # Send the API request\n",
    "    response = requests.get(ENDPOINT, params=params, timeout=10)\n",
    "\n",
    "    # Parse the JSON response\n",
    "    data = response.json()\n",
    "\n",
    "    paper_list = []\n",
    "    # Extract the relevant information from the response\n",
    "    if data[\"status\"] == \"ok\":\n",
    "        papers = data[\"message\"][\"items\"]\n",
    "        if len(papers) > 0:\n",
    "            for paper in papers:\n",
    "                paper_list.append(paper)\n",
    "    return paper_list\n",
    "\n",
    "keywords = [\"machine learning\", \"deep learning\", \"artificial intelligence\"]\n",
    "dois = crossref_keywords_search(keywords, 10)\n",
    "print(json.dumps(dois))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\" OR \".join(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def search_similar_papers(keywords):\n",
    "    base_url = 'https://api.crossref.org/works'\n",
    "    \n",
    "    # Create the query string with the specified keywords\n",
    "    query = ' '.join(f'title:{keyword} abstract:{keyword}' for keyword in keywords)\n",
    "    \n",
    "    # Prepare the request URL\n",
    "    url = f'{base_url}?query={query}&rows=10'  # Limiting the response to 10 papers\n",
    "    \n",
    "    try:\n",
    "        # Send the HTTP GET request\n",
    "        response = requests.get(url)\n",
    "        \n",
    "        # Check if the request was successful (status code 200)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            \n",
    "            # Extract the relevant information from the response\n",
    "            papers = data['message']['items']\n",
    "            \n",
    "            # Process the papers\n",
    "            for paper in papers:\n",
    "                title = paper['title'][0]\n",
    "                authors = \"\"\n",
    "                if paper.get(\"author\") != None:\n",
    "                    lst_authors = paper.get(\"author\")\n",
    "                    for author in lst_authors:\n",
    "                        auth_name = author[\"given\"] + \" \" + author[\"family\"]\n",
    "                        authors = authors + auth_name + \", \"\n",
    "                \n",
    "                doi = paper['DOI']\n",
    "                \n",
    "                # Print the information\n",
    "                print(f'Title: {title}')\n",
    "                print(f'Authors: {authors}')\n",
    "                print(f'DOI: {doi}')\n",
    "                print('---')\n",
    "        else:\n",
    "            print(f'Request failed with status code {response.status_code}')\n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f'An error occurred: {e}')\n",
    "\n",
    "# Example usage\n",
    "keywords = ['finger joint montions', 'spherical rolling fingertips', 'handcrafted control', 'sophisticated object manipulation', 'roller grasper']\n",
    "search_similar_papers(keywords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = [True, True, True, True]\n",
    "t\n",
    "if not any(t):\n",
    "    print(\"True\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyvis.network import Network\n",
    "import networkx as nx\n",
    "\n",
    "# Create a sample network graph using NetworkX\n",
    "G = nx.Graph()\n",
    "G.add_edges_from([(1, 2), (2, 3), (3, 4), (4, 1)])\n",
    "\n",
    "# Create a PyVis Network object\n",
    "net = Network(notebook=True)\n",
    "\n",
    "# Add nodes and edges to the PyVis Network\n",
    "for node in G.nodes():\n",
    "    net.add_node(node, label=f'Node {node}')\n",
    "\n",
    "for edge in G.edges():\n",
    "    net.add_edge(edge[0], edge[1])\n",
    "\n",
    "# Define the click handler function\n",
    "def show_text(node_id):\n",
    "    node = net.nodes[node_id]\n",
    "    if 'title' in node:\n",
    "        del node['title']\n",
    "    else:\n",
    "        node['title'] = f'This is Node {node_id}'\n",
    "\n",
    "# Bind the click handler to the 'on_click' event\n",
    "net.add_event_listener(\"selectNode\", show_text)\n",
    "\n",
    "# Show the network graph\n",
    "net.show(\"example.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
